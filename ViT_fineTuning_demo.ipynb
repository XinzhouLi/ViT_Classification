{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT fine tuning with medical image dataset\n",
    "\n",
    "This demo is going to use the SPMS vs RRMS npy dataset to fine tuning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import torch   \n",
    "import torch.nn as nn  \n",
    "from transformers import ViTModel, ViTConfig  \n",
    "from torchvision import transforms  \n",
    "from torch.optim import Adam  \n",
    "from torch.utils.data import DataLoader  \n",
    "from tqdm import tqdm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else (\"mps\" if use_mps else \"cpu\"))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):  \n",
    "  \n",
    "    def __init__(self, input_data):  \n",
    "    \n",
    "        self.input_data = input_data  \n",
    "        # Transform input data  \n",
    "        self.transform = transforms.Compose([  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Resize((224, 224), antialias=True),  \n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],  \n",
    "        std=[0.5, 0.5, 0.5])  \n",
    "        ])  \n",
    "    \n",
    "    def __len__(self):  \n",
    "        return len(self.input_data)  \n",
    "    \n",
    "    def get_images(self, idx):  \n",
    "        return self.transform(self.input_data[idx]['image'])  \n",
    "    \n",
    "    def get_labels(self, idx):  \n",
    "        return self.input_data[idx]['label']  \n",
    "    \n",
    "    def __getitem__(self, idx):  \n",
    "        # Get input data in a batch  \n",
    "        train_images = self.get_images(idx)  \n",
    "        train_labels = self.get_labels(idx)  \n",
    "        return train_images, train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):  \n",
    "  \n",
    "    def __init__(self, config=ViTConfig(), num_labels=20,  \n",
    "        model_checkpoint='google/vit-base-patch16-224-in21k'):  \n",
    "        \n",
    "        super(ViT, self).__init__()  \n",
    "        \n",
    "        self.vit = ViTModel.from_pretrained(model_checkpoint, add_pooling_layer=False)  \n",
    "        self.classifier = (  \n",
    "        nn.Linear(config.hidden_size, num_labels)  \n",
    "        )  \n",
    "    \n",
    "    def forward(self, x):  \n",
    "        \n",
    "        x = self.vit(x)['last_hidden_state']  \n",
    "        # Use the embedding of [CLS] token  \n",
    "        output = self.classifier(x[:, 0, :])  \n",
    "  \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(dataset, epochs, learning_rate, bs):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    use_mps = torch.backends.mps.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else (\"mps\" if use_mps else \"cpu\"))\n",
    "\n",
    "    # Load nodel, loss function, and optimizer\n",
    "    model = ViT().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Load batch image\n",
    "    train_dataset = ImageDataset(dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, num_workers=1, batch_size=bs, shuffle=True)\n",
    "\n",
    "    # Fine tuning loop\n",
    "    for i in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0.0\n",
    "\n",
    "        for train_image, train_label in tqdm(train_dataloader):\n",
    "            output = model(train_image.to(device))\n",
    "            loss = criterion(output, train_label.to(device))\n",
    "            acc = (output.argmax(dim=1) == train_label.to(device)).sum().item()\n",
    "            total_acc_train += acc\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(f'Epochs: {i + 1} | Loss: {total_loss_train / len(train_dataset): .3f} | Accuracy: {total_acc_train / len(train_dataset): .3f}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10 \n",
    "LEARNING_RATE = 1e-4 \n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model_train(dataset['train'], EPOCHS, LEARNING_RATE, BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
